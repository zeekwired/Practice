{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T00:37:27.673943Z",
     "start_time": "2023-02-08T00:37:23.956393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T00:38:18.806508Z",
     "start_time": "2023-02-08T00:37:27.674910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading dataset\n",
    "mnist = fetch_openml('mnist_784')\n",
    "# View the shape of the dataset\n",
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T00:38:19.024782Z",
     "start_time": "2023-02-08T00:38:18.808503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting features\n",
    "X = mnist.data\n",
    "# Setting target\n",
    "y = mnist.target\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate a model on train and test sets\n",
    "    \"\"\"\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    print('Classification report: \\n', classification_report(y_test, model.predict(X_test)))\n",
    "    print(confusion_matrix(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T00:38:19.039672Z",
     "start_time": "2023-02-08T00:38:19.026778Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "# Creating PCA object\n",
    "pca = PCA(n_components=.95)\n",
    "# Creating pipeline for StandardScaler and PCA\n",
    "transformer = make_pipeline(scaler, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T00:38:28.701999Z",
     "start_time": "2023-02-08T00:38:19.041668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1714\n",
      "           1       0.96      0.99      0.97      1977\n",
      "           2       0.95      0.94      0.94      1761\n",
      "           3       0.94      0.94      0.94      1806\n",
      "           4       0.94      0.94      0.94      1587\n",
      "           5       0.95      0.93      0.94      1607\n",
      "           6       0.96      0.98      0.97      1761\n",
      "           7       0.94      0.93      0.94      1878\n",
      "           8       0.97      0.90      0.93      1657\n",
      "           9       0.91      0.93      0.92      1752\n",
      "\n",
      "    accuracy                           0.95     17500\n",
      "   macro avg       0.95      0.95      0.95     17500\n",
      "weighted avg       0.95      0.95      0.95     17500\n",
      "\n",
      "[[1682    0    4    1    0    8   15    3    1    0]\n",
      " [   0 1962    7    1    2    0    1    2    1    1]\n",
      " [  16   21 1656   21    8    4   13   10    8    4]\n",
      " [   2    4   18 1704    3   15    3   28   15   14]\n",
      " [   0   14   14    1 1499    3    4    5    2   45]\n",
      " [   7    2    2   42    8 1500   24    2   13    7]\n",
      " [  14    2    6    0    8    9 1718    0    4    0]\n",
      " [   2   20   10    2   20    2    0 1755    2   65]\n",
      " [  15   18   17   26   11   41    9   14 1488   18]\n",
      " [  10    5   10   16   32    3    0   47    7 1622]]\n"
     ]
    }
   ],
   "source": [
    "# Creating first KNN model with PCA pipeline\n",
    "knn1 = make_pipeline(transformer, KNeighborsClassifier())\n",
    "# Fitting first KNN model\n",
    "knn1.fit(X_train, y_train)\n",
    "\n",
    "evaluate(knn1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For this assignment, VSCode doesn't have the %%time function since the jupyter notebook extension comes with execution time built into the cell as default (Time took to execute: 28.2 sec). I commented it out for you so that you can run it and see the result on your end. \n",
    "> \n",
    "> - I know that jupyter notebook is required but I have dojo-env loaded and anaconda. Also, I like VSCode using my computers resources (they tend to be faster than client-server IDE's). So trying to be honest I'm going to be stubborn about switching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T00:38:55.030195Z",
     "start_time": "2023-02-08T00:38:33.125482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1714\n",
      "           1       0.95      0.99      0.97      1977\n",
      "           2       0.95      0.93      0.94      1761\n",
      "           3       0.93      0.94      0.94      1806\n",
      "           4       0.94      0.93      0.94      1587\n",
      "           5       0.94      0.93      0.94      1607\n",
      "           6       0.96      0.97      0.97      1761\n",
      "           7       0.94      0.93      0.93      1878\n",
      "           8       0.97      0.89      0.93      1657\n",
      "           9       0.90      0.92      0.91      1752\n",
      "\n",
      "    accuracy                           0.94     17500\n",
      "   macro avg       0.94      0.94      0.94     17500\n",
      "weighted avg       0.94      0.94      0.94     17500\n",
      "\n",
      "[[1681    1    5    2    0    8   14    2    1    0]\n",
      " [   0 1962    8    1    2    0    1    1    1    1]\n",
      " [  18   23 1646   25    7    6   13   11    8    4]\n",
      " [   2    6   21 1703    3   16    2   26   14   13]\n",
      " [   0   16   14    1 1480    1    5    7    3   60]\n",
      " [   8    4    2   41    9 1498   22    3   11    9]\n",
      " [  14    4    7    0    8    9 1716    0    3    0]\n",
      " [   2   22    9    2   24    1    0 1747    1   70]\n",
      " [  14   22   16   31   10   49    7   13 1477   18]\n",
      " [   9    6    9   18   33    3    0   54    6 1614]]\n"
     ]
    }
   ],
   "source": [
    "# Creating second KNN model without PCA pipeline\n",
    "knn2 = make_pipeline(scaler, KNeighborsClassifier())\n",
    "knn2.fit(X_train, y_train)\n",
    "\n",
    "evaluate(knn2, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### a. Which model performed the best on the test set?\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### b. Which model was the fastest at making predictions?\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "dojo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "4b31512f92221b1229e52ed4f26b9fed1a2ab2027382c38a12d18717dccb8195"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
